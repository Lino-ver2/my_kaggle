{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mymodule'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mセル1 を /Users/lino/Desktop/kaggle/Novozymes_cmp/training/cluster_val.ipynb\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lino/Desktop/kaggle/Novozymes_cmp/training/cluster_val.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlgb\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lino/Desktop/kaggle/Novozymes_cmp/training/cluster_val.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m KMeans\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lino/Desktop/kaggle/Novozymes_cmp/training/cluster_val.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmymodule\u001b[39;00m \u001b[39mimport\u001b[39;00m except_outlier, pre_train_test, spearman_and_mse\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mymodule'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from mymodule import except_outlier, pre_train_test, spearman_and_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv('dataset/featured//base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = ['protein_sequence', 'pH', 'B', 'J', 'O', 'U', 'X', 'Z']\n",
    "\n",
    "df = except_outlier(base_df, 'sequence_len')\n",
    "idx, x, y = pre_train_test(df, True, drops=drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = x.to_numpy()\n",
    "# clustering\n",
    "n_clusters = 4\n",
    "km_model = KMeans(n_clusters=n_clusters)\n",
    "cluster_id = km_model.fit_predict(cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = pd.Series(cluster_id)\n",
    "c_y = pd.concat((y, cid),axis=1)\n",
    "c_y.columns = ['tm', 'cluster_id']\n",
    "c_x = x.copy()\n",
    "c_x['cluster_id'] = cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[702]\ttraining's l1: 5.93893\tvalid_1's l1: 7.5136\n",
      "correlation: 0.99999  | mse: 1e+02\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[655]\ttraining's l1: 6.1102\tvalid_1's l1: 6.64933\n",
      "correlation: 0.99999  | mse: 9e+01\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's l1: 7.46063\tvalid_1's l1: 12.3903\n",
      "correlation: 0.99999  | mse: 3e+02\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=50, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's l1: 7.53402\tvalid_1's l1: 6.43252\n",
      "correlation: 0.99994  | mse: 1e+02\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l1', \n",
    "    'metric': 'mean_absolute_error',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 32,\n",
    "    'subsample': 0.7,\n",
    "    'subsample_freq': 1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'min_sum_hessian_in_leaf': 50,\n",
    "    'n_estimators': 10000,\n",
    "    \"random_state\": 123,\n",
    "    \"importance_type\": \"gain\",\n",
    "}\n",
    "\n",
    "file_path = 'models/test/cluster_test'\n",
    "\n",
    "for n in range(n_clusters):\n",
    "    train_x = c_x[c_x['cluster_id']!=n]\n",
    "    train_y = c_y[c_y['cluster_id']!=n]\n",
    "    val_x = c_x[c_x['cluster_id']==n]\n",
    "    val_y = c_y[c_y['cluster_id']==n]\n",
    "\n",
    "    train_x, train_y, val_x, val_y = [i.drop('cluster_id', axis=1).to_numpy()\n",
    "                                    for i in [train_x, train_y, val_x, val_y]]\n",
    "    train_y = train_y.reshape(-1)\n",
    "    val_y = val_y.reshape(-1)\n",
    "                                    \n",
    "\n",
    "    # train model\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(\n",
    "        train_x, train_y,\n",
    "        eval_set=[(train_x, train_y), (val_x, val_y)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=1000)\n",
    "\n",
    "    # evaluate prediction with spreaman_correlation_coefficient\n",
    "    y_pred = model.predict(val_x)\n",
    "    corr, mse = spearman_and_mse(val_y, y_pred)\n",
    "    print('correlation: {:.5}'.format(corr,),' | mse: {:.1}'.format(mse))\n",
    "    \n",
    "    # save model to file_path\n",
    "    path = file_path + f'_fold{n}'\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "596b88989fc0dc1fed1e4e461c9c9f08188a37ef0bdca6efc263739311be1bbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
